{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.1 ('.venv': poetry)' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"d:/my files_/GIT/Job Applications/Mentorcruise/Tunyi/.venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from textstat.textstat import textstatistics,legacy_round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.1 ('.venv': poetry)' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"d:/my files_/GIT/Job Applications/Mentorcruise/Tunyi/.venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Splits the text into sentences, using\n",
    "# Spacy's sentence segmentation which can\n",
    "# be found at https://spacy.io/usage/spacy-101\n",
    "def break_sentences(text):\n",
    "\tnlp = spacy.load('en_core_web_sm')\n",
    "\tdoc = nlp(text)\n",
    "\treturn list(doc.sents)\n",
    "\n",
    "# Returns Number of Words in the text\n",
    "def word_count(text):\n",
    "\tsentences = break_sentences(text)\n",
    "\twords = 0\n",
    "\tfor sentence in sentences:\n",
    "\t\twords += len([token for token in sentence])\n",
    "\treturn words\n",
    "\n",
    "# Returns the number of sentences in the text\n",
    "def sentence_count(text):\n",
    "\tsentences = break_sentences(text)\n",
    "\treturn len(sentences)\n",
    "\n",
    "# Returns average sentence length\n",
    "def avg_sentence_length(text):\n",
    "\twords = word_count(text)\n",
    "\tsentences = sentence_count(text)\n",
    "\taverage_sentence_length = float(words / sentences)\n",
    "\treturn average_sentence_length\n",
    "\n",
    "# Textstat is a python package, to calculate statistics from\n",
    "# text to determine readability,\n",
    "# complexity and grade level of a particular corpus.\n",
    "# Package can be found at https://pypi.python.org/pypi/textstat\n",
    "def syllables_count(word):\n",
    "\treturn textstatistics().syllable_count(word)\n",
    "\n",
    "# Returns the average number of syllables per\n",
    "# word in the text\n",
    "def avg_syllables_per_word(text):\n",
    "\tsyllable = syllables_count(text)\n",
    "\twords = word_count(text)\n",
    "\tASPW = float(syllable) / float(words)\n",
    "\treturn legacy_round(ASPW, 1)\n",
    "\n",
    "# Return total Difficult Words in a text\n",
    "def difficult_words(text):\n",
    "\t\n",
    "\tnlp = spacy.load('en_core_web_sm')\n",
    "\tdoc = nlp(text)\n",
    "\t# Find all words in the text\n",
    "\twords = []\n",
    "\tsentences = break_sentences(text)\n",
    "\tfor sentence in sentences:\n",
    "\t\twords += [str(token) for token in sentence]\n",
    "\n",
    "\t# difficult words are those with syllables >= 2\n",
    "\t# easy_word_set is provide by Textstat as\n",
    "\t# a list of common words\n",
    "\tdiff_words_set = set()\n",
    "\t\n",
    "\tfor word in words:\n",
    "\t\tsyllable_count = syllables_count(word)\n",
    "\t\tif word not in nlp.Defaults.stop_words and syllable_count >= 2:\n",
    "\t\t\tdiff_words_set.add(word)\n",
    "\n",
    "\treturn len(diff_words_set)\n",
    "\n",
    "# A word is polysyllablic if it has more than 3 syllables\n",
    "# this functions returns the number of all such words\n",
    "# present in the text\n",
    "def poly_syllable_count(text):\n",
    "\tcount = 0\n",
    "\twords = []\n",
    "\tsentences = break_sentences(text)\n",
    "\tfor sentence in sentences:\n",
    "\t\twords += [token for token in sentence]\n",
    "\t\n",
    "\n",
    "\tfor word in words:\n",
    "\t\tsyllable_count = syllables_count(word)\n",
    "\t\tif syllable_count >= 3:\n",
    "\t\t\tcount += 1\n",
    "\treturn count\n",
    "\n",
    "\n",
    "def flesch_reading_ease(text):\n",
    "\t\"\"\"\n",
    "\t\tImplements Flesch Formula:\n",
    "\t\tReading Ease score = 206.835 - (1.015 × ASL) - (84.6 × ASW)\n",
    "\t\tHere,\n",
    "\t\tASL = average sentence length (number of words\n",
    "\t\t\t\tdivided by number of sentences)\n",
    "\t\tASW = average word length in syllables (number of syllables\n",
    "\t\t\t\tdivided by number of words)\n",
    "\t\"\"\"\n",
    "\tFRE = 206.835 - float(1.015 * avg_sentence_length(text)) -\\\n",
    "\t\tfloat(84.6 * avg_syllables_per_word(text))\n",
    "\treturn legacy_round(FRE, 2)\n",
    "\n",
    "\n",
    "def gunning_fog(text):\n",
    "\tper_diff_words = (difficult_words(text) / word_count(text) * 100) + 5\n",
    "\tgrade = 0.4 * (avg_sentence_length(text) + per_diff_words)\n",
    "\treturn grade\n",
    "\n",
    "\n",
    "def smog_index(text):\n",
    "\t\"\"\"\n",
    "\t\tImplements SMOG Formula / Grading\n",
    "\t\tSMOG grading = 3 + ?polysyllable count.\n",
    "\t\tHere,\n",
    "\t\tpolysyllable count = number of words of more\n",
    "\t\tthan two syllables in a sample of 30 sentences.\n",
    "\t\"\"\"\n",
    "\n",
    "\tif sentence_count(text) >= 3:\n",
    "\t\tpoly_syllab = poly_syllable_count(text)\n",
    "\t\tSMOG = (1.043 * (30*(poly_syllab / sentence_count(text)))**0.5) \\\n",
    "\t\t\t\t+ 3.1291\n",
    "\t\treturn legacy_round(SMOG, 1)\n",
    "\telse:\n",
    "\t\treturn 0\n",
    "\n",
    "\n",
    "def dale_chall_readability_score(text):\n",
    "\t\"\"\"\n",
    "\t\tImplements Dale Challe Formula:\n",
    "\t\tRaw score = 0.1579*(PDW) + 0.0496*(ASL) + 3.6365\n",
    "\t\tHere,\n",
    "\t\t\tPDW = Percentage of difficult words.\n",
    "\t\t\tASL = Average sentence length\n",
    "\t\"\"\"\n",
    "\twords = word_count(text)\n",
    "\t# Number of words not termed as difficult words\n",
    "\tcount = word_count - difficult_words(text)\n",
    "\tif words > 0:\n",
    "\n",
    "\t\t# Percentage of words not on difficult word list\n",
    "\n",
    "\t\tper = float(count) / float(words) * 100\n",
    "\t\n",
    "\t# diff_words stores percentage of difficult words\n",
    "\tdiff_words = 100 - per\n",
    "\n",
    "\traw_score = (0.1579 * diff_words) + \\\n",
    "\t\t\t\t(0.0496 * avg_sentence_length(text))\n",
    "\t\n",
    "\t# If Percentage of Difficult Words is greater than 5 %, then;\n",
    "\t# Adjusted Score = Raw Score + 3.6365,\n",
    "\t# otherwise Adjusted Score = Raw Score\n",
    "\n",
    "\tif diff_words > 5:\t\n",
    "\n",
    "\t\traw_score += 3.6365\n",
    "\t\t\n",
    "\treturn legacy_round(score, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0438f209f3fb1f9574279c824dea67b41d8e82e2f705e2400e78874b8634cd1d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
